{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "from py3nvml import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import paramiko\n",
    "import psutil\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1;3;2;4;5;6;7;8;10;9;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AuthenticationException",
     "evalue": "Authentication failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/data/theory/robustopt/krisgrg/.conda/envs/rob/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/data/theory/robustopt/krisgrg/.conda/envs/rob/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-16-f4c04fe93974>\", line 17, in populate_df\n    ssh_client.connect(hostname=machine,username='krisgrg',password='2cqlo7desetiednO')\n  File \"/data/theory/robustopt/krisgrg/.conda/envs/rob/lib/python3.6/site-packages/paramiko/client.py\", line 446, in connect\n    passphrase,\n  File \"/data/theory/robustopt/krisgrg/.conda/envs/rob/lib/python3.6/site-packages/paramiko/client.py\", line 764, in _auth\n    raise saved_exception\n  File \"/data/theory/robustopt/krisgrg/.conda/envs/rob/lib/python3.6/site-packages/paramiko/client.py\", line 751, in _auth\n    self._transport.auth_password(username, password)\n  File \"/data/theory/robustopt/krisgrg/.conda/envs/rob/lib/python3.6/site-packages/paramiko/transport.py\", line 1509, in auth_password\n    return self.auth_handler.wait_for_response(my_event)\n  File \"/data/theory/robustopt/krisgrg/.conda/envs/rob/lib/python3.6/site-packages/paramiko/auth_handler.py\", line 250, in wait_for_response\n    raise e\nparamiko.ssh_exception.AuthenticationException: Authentication failed.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAuthenticationException\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f4c04fe93974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_machines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulate_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_machines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mhtml_top\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m<\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rob/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/rob/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: Authentication failed."
     ]
    }
   ],
   "source": [
    "with open('/data/theory/robustopt/krisgrg/pass.txt', 'r') as fp:\n",
    "    pswd = fp.read().rstrip()\n",
    "\n",
    "def populate_df(ssh_client, machine): \n",
    "    i = int(machine.split('-')[-1])\n",
    "    print(f'{i};')\n",
    "    flag_done = False \n",
    "    _, stdout, stderr = ssh_client.exec_command('source /data/theory/robustopt/krisgrg/.zshrc \\n conda activate rob \\n python3 /data/theory/robustopt/krisgrg/adversarial_generalization/cl.py')\n",
    "    for _ in range(5):\n",
    "        time.sleep(1)\n",
    "        if stdout.channel.eof_received:\n",
    "            stdout.channel.close()\n",
    "            z = stdout.readline()\n",
    "            print(z.split(';'))\n",
    "            free_gpus, mem_used, gpu_util, cpu_util, __ = z.split(';')\n",
    "\n",
    "            for j in range(deviceCount):\n",
    "                handle = nvmlDeviceGetHandleByIndex(j)\n",
    "                mem_info = nvmlDeviceGetMemoryInfo(handle)\n",
    "                util = nvmlDeviceGetUtilizationRates(handle)\n",
    "\n",
    "            a.at[i, 'node'] = machine\n",
    "            a.at[i, 'mem_used'] = str(round(mem_info.used / mem_info.total, 2)) + '%'\n",
    "            z = [float(util) for (i, util) in enumerate(gpu_util.split(', '))]\n",
    "            a.at[i, 'GPU utilization (only taken)'] = str(np.mean(z)) + '%'\n",
    "            a.at[i, 'CPU utilization'] = str(cpu_util) + '%'\n",
    "            a.at[i, 'Free GPUs'] = free_gpus\n",
    "            flag_done = True\n",
    "            break\n",
    "\n",
    "    if not flag_done:\n",
    "        a.at[i, ''] = 'UNREACHABLE'\n",
    "    else:\n",
    "        a.at[i, ''] = ''\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    nvmlInit()\n",
    "    deviceCount = nvmlDeviceGetCount()\n",
    "\n",
    "    a = pd.DataFrame(columns=['node', 'Free GPUs', 'mem_used', 'GPU utilization (only taken)', 'CPU utilization', ''])\n",
    "\n",
    "    list_machines = ['deep-gpu-1', 'deep-gpu-2', 'deep-gpu-3', 'deep-gpu-4', 'deep-gpu-5', 'deep-gpu-6', 'deep-gpu-7', 'deep-gpu-8', 'deep-gpu-9', 'deep-gpu-10']\n",
    "    ssh_clients = []\n",
    "    for machine in list_machines:\n",
    "        ssh_client = paramiko.SSHClient()\n",
    "        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        ssh_client.connect(hostname=machine,username='krisgrg', password=pswd)\n",
    "        ssh_clients.append(ssh_client)\n",
    "\n",
    "    with Pool(processes=len(list_machines)) as p:\n",
    "        p.map(populate_df, list_machines)\n",
    "    html_top = \"<html>\\\n",
    "        <head>\\\n",
    "        </head>\\\n",
    "        <meta http-equiv='refresh' content='10' />\\\n",
    "        <body>\"\n",
    "    html_str = html_top + a.to_html(index=False) + '</body>'\n",
    "    with open('/afs/csail.mit.edu/u/k/krisgrg/public_html/cluster.html', 'w') as fp:\n",
    "        fp.write(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utilization.gpu [%], utilization.memory [%], memory.total [MiB], memory.free [MiB], memory.used [MiB]\n",
      "0 %, 0 %, 11178 MiB, 10485 MiB, 693 MiB\n",
      "0 %, 0 %, 11178 MiB, 11168 MiB, 10 MiB\n",
      "0 %, 0 %, 11178 MiB, 11168 MiB, 10 MiB\n",
      "0 %, 0 %, 11178 MiB, 11168 MiB, 10 MiB\n",
      "0 %, 0 %, 11178 MiB, 11168 MiB, 10 MiB\n",
      "0 %, 0 %, 11178 MiB, 11168 MiB, 10 MiB\n",
      "0 %, 0 %, 11178 MiB, 11168 MiB, 10 MiB\n",
      "0 %, 0 %, 11178 MiB, 11168 MiB, 10 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=utilization.gpu,utilization.memory,memory.total,memory.free,memory.used --format=csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  2 03:57:54 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 29%   31C    P8     9W / 250W |    693MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 29%   25C    P8     8W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:07:00.0 Off |                  N/A |\n",
      "| 29%   32C    P8     8W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 29%   30C    P8    11W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 29%   31C    P8     8W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 29%   30C    P8     7W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 29%   31C    P8     8W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 29%   30C    P8     8W / 250W |     10MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     10760      C   /opt/miniconda/bin/python                    683MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA System Management Interface -- v418.87.01\n",
      "\n",
      "NVSMI provides monitoring information for Tesla and select Quadro devices.\n",
      "The data is presented in either a plain text or an XML format, via stdout or a file.\n",
      "NVSMI also provides several management operations for changing the device state.\n",
      "\n",
      "Note that the functionality of NVSMI is exposed through the NVML C-based\n",
      "library. See the NVIDIA developer website for more information about NVML.\n",
      "Python wrappers to NVML are also available.  The output of NVSMI is\n",
      "not guaranteed to be backwards compatible; NVML and the bindings are backwards\n",
      "compatible.\n",
      "\n",
      "http://developer.nvidia.com/nvidia-management-library-nvml/\n",
      "http://pypi.python.org/pypi/nvidia-ml-py/\n",
      "Supported products:\n",
      "- Full Support\n",
      "    - All Tesla products, starting with the Kepler architecture\n",
      "    - All Quadro products, starting with the Kepler architecture\n",
      "    - All GRID products, starting with the Kepler architecture\n",
      "    - GeForce Titan products, starting with the Kepler architecture\n",
      "- Limited Support\n",
      "    - All Geforce products, starting with the Kepler architecture\n",
      "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
      "\n",
      "    -h,   --help                Print usage information and exit.\n",
      "\n",
      "  LIST OPTIONS:\n",
      "\n",
      "    -L,   --list-gpus           Display a list of GPUs connected to the system.\n",
      "\n",
      "    -B,   --list-blacklist-gpus Display a list of blacklisted GPUs in the system.\n",
      "\n",
      "  SUMMARY OPTIONS:\n",
      "\n",
      "    <no arguments>              Show a summary of GPUs connected to the system.\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "\n",
      "  QUERY OPTIONS:\n",
      "\n",
      "    -q,   --query               Display GPU or Unit info.\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -u,   --unit                Show unit, rather than GPU, attributes.\n",
      "    -i,   --id=                 Target a specific GPU or Unit.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -x,   --xml-format          Produce XML output.\n",
      "          --dtd                 When showing xml output, embed DTD.\n",
      "    -d,   --display=            Display only selected information: MEMORY,\n",
      "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\n",
      "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\n",
      "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS, FBC_STATS\n",
      "                                Flags can be combined with comma e.g. ECC,POWER.\n",
      "                                Sampling data with max/min/avg is also returned \n",
      "                                for POWER, UTILIZATION and CLOCK display types.\n",
      "                                Doesn't work with -u or -x flags.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "\n",
      "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
      "\n",
      "  SELECTIVE QUERY OPTIONS:\n",
      "\n",
      "    Allows the caller to pass an explicit list of properties to query.\n",
      "\n",
      "    [one of]\n",
      "\n",
      "    --query-gpu=                Information about GPU.\n",
      "                                Call --help-query-gpu for more info.\n",
      "    --query-supported-clocks=   List of supported clocks.\n",
      "                                Call --help-query-supported-clocks for more info.\n",
      "    --query-compute-apps=       List of currently active compute processes.\n",
      "                                Call --help-query-compute-apps for more info.\n",
      "    --query-accounted-apps=     List of accounted compute processes.\n",
      "                                Call --help-query-accounted-apps for more info.\n",
      "    --query-retired-pages=      List of device memory pages that have been retired.\n",
      "                                Call --help-query-retired-pages for more info.\n",
      "\n",
      "    [mandatory]\n",
      "\n",
      "    --format=                   Comma separated list of format options:\n",
      "                                  csv - comma separated values (MANDATORY)\n",
      "                                  noheader - skip the first line with column headers\n",
      "                                  nounits - don't print units for numerical\n",
      "                                             values\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU or Unit.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
      "\n",
      "  DEVICE MODIFICATION OPTIONS:\n",
      "\n",
      "    [any one of]\n",
      "\n",
      "    -pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED\n",
      "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\n",
      "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\n",
      "    -c,   --compute-mode=       Set MODE for compute applications:\n",
      "                                0/DEFAULT, 1/EXCLUSIVE_PROCESS,\n",
      "                                2/PROHIBITED\n",
      "          --gom=                Set GPU Operation Mode:\n",
      "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\n",
      "    -r    --gpu-reset           Trigger reset of the GPU.\n",
      "                                Can be used to reset the GPU HW state in situations\n",
      "                                that would otherwise require a machine reboot.\n",
      "                                Typically useful if a double bit ECC error has\n",
      "                                occurred.\n",
      "                                Reset operations are not guarenteed to work in\n",
      "                                all cases and should be used with caution.\n",
      "    -vm   --virt-mode=          Switch GPU Virtualization Mode:\n",
      "                                Sets GPU virtualization mode to 3/VGPU or 4/VSGA\n",
      "                                Virtualization mode of a GPU can only be set when\n",
      "                                it is running on a hypervisor.\n",
      "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\n",
      "                                    pair (e.g. 1500,1500) that defines the range \n",
      "                                    of desired locked GPU clock speed in MHz.\n",
      "                                    Setting this will supercede application clocks\n",
      "                                    and take effect regardless if an app is running.\n",
      "                                    Input can also be a singular desired clock value\n",
      "                                    (e.g. <GpuClockValue>).\n",
      "    -rgc  --reset-gpu-clocks\n",
      "                                Resets the Gpu clocks to the default values.\n",
      "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\n",
      "                                    pair (e.g. 2000,800) that defines GPU's\n",
      "                                    speed in MHz while running applications on a GPU.\n",
      "    -rac  --reset-applications-clocks\n",
      "                                Resets the applications clocks to the default values.\n",
      "    -acp  --applications-clocks-permission=\n",
      "                                Toggles permission requirements for -ac and -rac commands:\n",
      "                                0/UNRESTRICTED, 1/RESTRICTED\n",
      "    -pl   --power-limit=        Specifies maximum power management limit in watts.\n",
      "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\n",
      "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\n",
      "                                Only on supported devices starting from the Volta series.\n",
      "                                Requires administrator privileges.\n",
      "                                0/RESTORE_DEFAULT, 1/OVERRIDE\n",
      "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\n",
      "    -caa  --clear-accounted-apps\n",
      "                                Clears all the accounted PIDs in the buffer.\n",
      "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\n",
      "                                or 1/ENABLED, enforcing the change only after the\n",
      "                                last boost client has exited.\n",
      "          --auto-boost-permission=\n",
      "                                Allow non-admin/root control over auto boost mode:\n",
      "                                0/UNRESTRICTED, 1/RESTRICTED\n",
      "   [plus optional]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU.\n",
      "\n",
      "  UNIT MODIFICATION OPTIONS:\n",
      "\n",
      "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\n",
      "\n",
      "   [plus optional]\n",
      "\n",
      "    -i,   --id=                 Target a specific Unit.\n",
      "\n",
      "  SHOW DTD OPTIONS:\n",
      "\n",
      "          --dtd                 Print device DTD and exit.\n",
      "\n",
      "     [plus optional]\n",
      "\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -u,   --unit                Show unit, rather than device, DTD.\n",
      "\n",
      "    --debug=                    Log encrypted debug information to a specified file. \n",
      "\n",
      " STATISTICS: (EXPERIMENTAL)\n",
      "    stats                       Displays device statistics. \"nvidia-smi stats -h\" for more information.\n",
      "\n",
      " Device Monitoring:\n",
      "    dmon                        Displays device stats in scrolling format.\n",
      "                                \"nvidia-smi dmon -h\" for more information.\n",
      "\n",
      "    daemon                      Runs in background and monitor devices as a daemon process.\n",
      "                                This is an experimental feature. Not supported on Windows baremetal\n",
      "                                \"nvidia-smi daemon -h\" for more information.\n",
      "\n",
      "    replay                      Used to replay/extract the persistent stats generated by daemon.\n",
      "                                This is an experimental feature.\n",
      "                                \"nvidia-smi replay -h\" for more information.\n",
      "\n",
      " Process Monitoring:\n",
      "    pmon                        Displays process stats in scrolling format.\n",
      "                                \"nvidia-smi pmon -h\" for more information.\n",
      "\n",
      " TOPOLOGY:\n",
      "    topo                        Displays device/system topology. \"nvidia-smi topo -h\" for more information.\n",
      "\n",
      " DRAIN STATES:\n",
      "    drain                       Displays/modifies GPU drain states for power idling. \"nvidia-smi drain -h\" for more information.\n",
      "\n",
      " NVLINK:\n",
      "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\n",
      "\n",
      " CLOCKS:\n",
      "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\n",
      "\n",
      " ENCODER SESSIONS:\n",
      "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\n",
      "\n",
      " FBC SESSIONS:\n",
      "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\n",
      "\n",
      " GRID vGPU:\n",
      "    vgpu                        Displays vGPU information. \"nvidia-smi vgpu -h\" for more information.\n",
      "\n",
      "Please see the nvidia-smi(1) manual page for more detailed information.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of valid properties to query for the switch \"--query-compute-apps=\":\n",
      "\n",
      "Section about Active Compute Processes properties\n",
      "List of processes having compute context on the device.\n",
      "\n",
      "\"timestamp\"\n",
      "The timestamp of where the query was made in format \"YYYY/MM/DD HH:MM:SS.msec\".\n",
      "\n",
      "\"gpu_name\"\n",
      "The official product name of the GPU. This is an alphanumeric string. For all products.\n",
      "\n",
      "\"gpu_bus_id\"\n",
      "PCI bus id as \"domain:bus:device.function\", in hex.\n",
      "\n",
      "\"gpu_serial\"\n",
      "This number matches the serial number physically printed on each board. It is a globally unique immutable alphanumeric value.\n",
      "\n",
      "\"gpu_uuid\"\n",
      "This value is the globally unique immutable alphanumeric identifier of the GPU. It does not correspond to any physical label on the board.\n",
      "\n",
      "\"pid\"\n",
      "Process ID of the compute application\n",
      "\n",
      "\"process_name\" or \"name\"\n",
      "Process Name\n",
      "\n",
      "\"used_gpu_memory\" or \"used_memory\"\n",
      "Amount memory used on the device by the context. Not available on Windows when running in WDDM mode because Windows KMD manages all the memory not NVIDIA driver.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --help-query-compute-apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid, process_name, used_gpu_memory [MiB], gpu_name\n",
      "10760, /opt/miniconda/bin/python, 683 MiB, GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-compute-apps=pid,process_name,used_memory,gpu_name --format=csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
